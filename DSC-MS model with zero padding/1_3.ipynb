{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Klv2shwqWzr0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Input: 8x8 mesh simulation\n",
        "Target: 64x64 mesh simulation\n",
        "Downsampled skip connection multi scale model with zero padding\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8E7bOeJ-nji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from copy import deepcopy\n",
        "import torchvision\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqV5Ww-N-nje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading training data\n",
        "\n",
        "train_y = []\n",
        "train_x = []\n",
        "\n",
        "for i in range(1, 101, 1):\n",
        "    temperature = \"{:.2f}\".format(0.01 * i)\n",
        "    \n",
        "    file_path = '8_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "       \n",
        "    x_input = [u,v,pressure]\n",
        "    train_x.append(x_input)\n",
        "\n",
        "    \n",
        "    file_path = '64_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "    y_output = [u,v,pressure]\n",
        "    train_y.append(y_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ajg8Hb-KoUrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading validation data\n",
        "\n",
        "val_y = []\n",
        "val_x = []\n",
        "\n",
        "for i in range(1, 20, 2):\n",
        "    temperature = 0.05 * i + 0.005\n",
        "    temperature = \"{:.3f}\".format(temperature)\n",
        "    \n",
        "    file_path = '8_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "    x_input = [u,v,pressure]\n",
        "    val_x.append(x_input)\n",
        "\n",
        "    \n",
        "    file_path = '64_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "    y_output = [u,v,pressure]\n",
        "    val_y.append(y_output)\n",
        "    \n",
        "    \n",
        "    temperature = 0.05 * i - 0.005\n",
        "    temperature = \"{:.3f}\".format(temperature)\n",
        "    \n",
        "    file_path = '8_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '8_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "   \n",
        "    x_input = [u,v,pressure]\n",
        "    val_x.append(x_input)\n",
        "\n",
        "    \n",
        "    file_path = '64_u_' + str(temperature) + '.txt'\n",
        "    u = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_v_' + str(temperature) + '.txt'\n",
        "    v = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_vel_' + str(temperature) + '.txt'\n",
        "    vel = np.loadtxt(file_path)\n",
        "    \n",
        "    file_path = '64_pressure_' + str(temperature) + '.txt'\n",
        "    pressure = np.loadtxt(file_path)\n",
        "    \n",
        "    y_output = [u,v,pressure]\n",
        "    val_y.append(y_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYi0R5Cx-njO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show(image):\n",
        "    plt.imshow(image, vmin=np.amin(image), vmax=np.amax(image), cmap='hsv')\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RnGLMIjxpzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class dataset(Dataset):\n",
        "    def __init__(self, train_x, train_y):\n",
        "        self.x = train_x\n",
        "        self.y = train_y\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "    def __getitem__(self, index):\n",
        "        return self.x[index], self.y[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5fmpbHM-njm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activate = torch.nn.Tanh()\n",
        "tanh = torch.nn.Tanh()\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.bn0 = nn.BatchNorm2d(num_features = 3)\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.conv3 = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 2, stride = 2, padding = 0)\n",
        "        self.conv4 = nn.ConvTranspose2d(in_channels = 3, out_channels = 3, kernel_size = 4, stride = 2, padding = 1, output_padding=0)\n",
        "        self.conv5 = nn.ConvTranspose2d(in_channels = 3, out_channels = 3, kernel_size = 4, stride = 2, padding = 1, output_padding=0)\n",
        "        self.conv6 = nn.ConvTranspose2d(in_channels = 3, out_channels = 3, kernel_size = 4, stride = 2, padding = 1, output_padding=0)\n",
        "        \n",
        "        #kernel_size 13\n",
        "        self.bn7 = nn.BatchNorm2d(num_features = 3)\n",
        "        self.conv7 = nn.Conv2d(in_channels = 3, out_channels = 4, kernel_size = 13, stride = 1, padding = 6)\n",
        "        self.bn8 = nn.BatchNorm2d(num_features = 4)\n",
        "        self.conv8 = nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 13, stride = 1, padding = 6)\n",
        "        #kernel_size 9\n",
        "        self.bn9 = nn.BatchNorm2d(num_features = 3)\n",
        "        self.conv9  = nn.Conv2d(in_channels = 3, out_channels = 4, kernel_size = 9, stride = 1, padding = 4)\n",
        "        self.bn10 = nn.BatchNorm2d(num_features = 4)\n",
        "        self.conv10 = nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 9, stride = 1, padding = 4)\n",
        "        #kernel_size 5\n",
        "        self.bn11 = nn.BatchNorm2d(num_features = 3)\n",
        "        self.conv11 = nn.Conv2d(in_channels = 3, out_channels = 4, kernel_size = 5, stride = 1, padding = 2)\n",
        "        self.bn12 = nn.BatchNorm2d(num_features = 4)\n",
        "        self.conv12 = nn.Conv2d(in_channels = 4, out_channels = 8, kernel_size = 5, stride = 1, padding = 2)\n",
        "        #last conv layer\n",
        "        self.bn13 = nn.BatchNorm2d(num_features = 24)\n",
        "        self.conv13 = nn.Conv2d(in_channels = 24, out_channels = 12, kernel_size = 7, stride = 1, padding = 3)\n",
        "        self.bn14 = nn.BatchNorm2d(num_features = 12)\n",
        "        self.conv14 = nn.Conv2d(in_channels = 12, out_channels =  3, kernel_size = 5, stride = 1, padding = 2)\n",
        "        #Final output layer\n",
        "        self.bn_out = nn.BatchNorm2d(num_features = 3)\n",
        "        self.out = nn.Conv2d(in_channels = 3, out_channels = 3, kernel_size = 3, stride = 1, padding = 1)\n",
        "        \n",
        "    def forward(self, x_64):\n",
        "        \n",
        "        x_32 = activate(self.conv1(x_64))\n",
        "        x_16 = activate(self.conv2(x_32))\n",
        "        x_8  = activate(self.conv3(x_16))        \n",
        "        y_16 = activate(self.conv4(x_8))+x_16\n",
        "        y_32 = activate(self.conv5(y_16))+x_32\n",
        "        y_64 = activate(self.conv6(y_32))+x_64\n",
        "        \n",
        "        z_13 = self.bn7(x_64)\n",
        "        z_13 = self.conv7(z_13)\n",
        "        z_13 = activate(z_13)\n",
        "        z_13 = self.bn8(z_13)\n",
        "        z_13 = self.conv8(z_13)\n",
        "        z_13 = activate(z_13)\n",
        "        \n",
        "        z_9 = self.bn9(x_64)\n",
        "        z_9 = self.conv9(z_9)\n",
        "        z_9 = activate(z_9)\n",
        "        z_9 = self.bn10(z_9)\n",
        "        z_9 = self.conv10(z_9)\n",
        "        z_9 = activate(z_9)\n",
        "        \n",
        "        z_5 = self.bn11(x_64)\n",
        "        z_5 = self.conv11(z_5)\n",
        "        z_5 = activate(z_5)\n",
        "        z_5 = self.bn12(z_5)\n",
        "        z_5 = self.conv12(z_5)\n",
        "        z_5 = activate(z_5)\n",
        "        \n",
        "        z = torch.cat((z_13, z_9, z_5), 1)\n",
        "        z = self.bn13(z)\n",
        "        z = self.conv13(z)\n",
        "        z = activate(z)\n",
        "        z = self.bn14(z)\n",
        "        z = self.conv14(z)\n",
        "        z = activate(z)\n",
        "        \n",
        "        z = z+y_64\n",
        "        z = self.bn_out(z)\n",
        "        z = self.out(z)\n",
        "        z = tanh(z)+x_64.resize_(1,3,64,64)\n",
        "       \n",
        "        return z"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByD3Z4ip-njo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unpooling to 64x64 mesh simulation\n",
        "\n",
        "train_data_x = []\n",
        "val_data_x = []\n",
        "\n",
        "for i in range(len(train_x)):\n",
        "    u = cv2.resize(np.asarray(train_x[i][0]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    v = cv2.resize(np.asarray(train_x[i][1]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    pressure = cv2.resize(np.asarray(train_x[i][2]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    train_data_x.append(np.asarray([u,v,pressure]))\n",
        "    \n",
        "for i in range(len(val_x)):\n",
        "    u = cv2.resize(np.asarray(val_x[i][0]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    v = cv2.resize(np.asarray(val_x[i][1]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    pressure = cv2.resize(np.asarray(val_x[i][2]), dsize=(64, 64), interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    val_data_x.append(np.asarray([u,v,pressure]))\n",
        "\n",
        "train_data_x = np.asarray(train_data_x)    \n",
        "train_y = np.asarray(train_y)    \n",
        "val_data_x = np.asarray(val_data_x)    \n",
        "val_y = np.asarray(val_y)    \n",
        "    \n",
        "train_data = dataset(train_data_x, train_y)\n",
        "val_data = dataset(val_data_x, val_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YndTHQfV-njr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Conv1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.Conv3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose1d):\n",
        "        init.normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose2d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.ConvTranspose3d):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        if m.bias is not None:\n",
        "            init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.BatchNorm1d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm2d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.BatchNorm3d):\n",
        "        init.normal_(m.weight.data, mean=1, std=0.02)\n",
        "        init.constant_(m.bias.data, 0)\n",
        "    elif isinstance(m, nn.Linear):\n",
        "        init.xavier_normal_(m.weight.data)\n",
        "        init.normal_(m.bias.data)\n",
        "    elif isinstance(m, nn.LSTM):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.LSTMCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRU):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)\n",
        "    elif isinstance(m, nn.GRUCell):\n",
        "        for param in m.parameters():\n",
        "            if len(param.shape) >= 2:\n",
        "                init.orthogonal_(param.data)\n",
        "            else:\n",
        "                init.normal_(param.data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhliq7HM-njv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 1, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(val_data, batch_size = 1, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pg8z1dgM-njz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.MSELoss()\n",
        "net = Net()\n",
        "net.apply(weight_init)\n",
        "net = net.double()\n",
        "net = net.cuda()\n",
        "train_losses = []\n",
        "val_losses = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pU6GEBqbOeT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.5\n",
        "optimizer = optim.SGD(net.parameters(), lr = learning_rate, momentum = 0.9)\n",
        "#optimizer = optim.Adam(net.parameters(), lr = learning_rate, weight_decay = 1e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7sCQnRn-nj4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "running_loss = 0.0\n",
        "num_epochs = 601\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    validation_loss = 0.0\n",
        "    #print(\"Epoch: \",epoch+1)\n",
        "    for i, dat in enumerate((train_loader), 0):\n",
        "        inputs, labels = dat\n",
        "        inputs = inputs.resize_(1, 3, 64, 64)\n",
        "        labels = labels.resize_(1, 3, 64, 64)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        if(i==9 and epoch%25==0):\n",
        "            show(outputs[0][0].cpu().detach().numpy())\n",
        "            show(labels[0][0].cpu().detach().numpy())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    for i, dat in enumerate((test_loader), 0):\n",
        "        inputs, labels = dat\n",
        "        inputs = inputs.resize_(1, 3, 64, 64)\n",
        "        labels = labels.resize_(1, 3, 64, 64)\n",
        "        if torch.cuda.is_available():\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.step()\n",
        "        validation_loss += loss.item()\n",
        "    running_loss/=100.0\n",
        "    validation_loss/=20.0\n",
        "    print(\"Epoch: \",epoch+1,\" running_loss: \",running_loss*100, \"validation_loss: \",validation_loss*100.0)\n",
        "    train_losses.append(running_loss)\n",
        "    val_losses.append(validation_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iFGBE-vvXDH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "torch.save(net.state_dict(),'weights.pth')\n",
        "files.download('weights.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQKcj88R7CYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net.load_state_dict(torch.load(\"weights.pth\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jp1yS5E4UVB6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = np.asarray(train_losses)\n",
        "val_losses = np.asarray(val_losses)\n",
        "np.savetxt('train.txt', train_losses, delimiter = '\\t')\n",
        "np.savetxt('val.txt', val_losses, delimiter = '\\t')\n",
        "from google.colab import files\n",
        "files.download('train.txt')\n",
        "files.download('val.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}